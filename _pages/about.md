---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Chunmei Qing, Doctor, Associate Professor, Master's Supervisor, and a Young Innovative Talent in Ordinary Colleges and Universities of Guangdong Province. Since 2013, I have been an associate professor in the School of Electronic and Information Engineering at [South China University of Technology](https://www.scut.edu.cn/new/), Guangzhou, China. In recent years, I have focused on conducting research in cutting-edge interdisciplinary areas and major regional industrial needs, particularly in virtual reality technology, multimodal affective computing, and natural human-computer interaction. I have undertaken a total of 8 projects, including the National Natural Science Foundation and major scientific and technological projects in Guangdong Province, and have participated in 8 projects under the key research and development plan of the Ministry of Science and Technology, major scientific and technological projects in Guangdong Province, and significant livelihood technology projects in Guangzhou.

I have published over 60 papers in related fields, including important international journals and conferences such as IEEE TAF, IEEE TMM, IEEE TCSVT, AAAI, and CVPR, with more than 3,000 citations. I have 1 ESI highly cited hot paper (top 0.1% in SCI) and 2 highly cited papers. I have been granted over ten authorized invention patents and have applied for more than 30 invention patents. I serve as a reviewer for several journals and conferences, including IEEE TMM, TIP, CSVT, and CVPR. I received the Best Poster Presentation Award at BICS 2023, the Best Student Paper Award at ICCSS 2017, and a Best Paper Nomination at ICIP 2017.

My research interest includes affective computing, virtual reality, human-computer interaction and computer vision. I have published more than 60 papers with total <a href='https://scholar.google.com/citations?user=soX8e10AAAAJ'>google scholar citations <strong><span id='total_cit'>4700+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=soX8e10AAAAJ'><img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fapifoxmock.com%2Fm1%2F5442790-5117933-default%2Fshields&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üìñ Educations
<!-- -*2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.-->
- *2006.10-2009.12*, Ph.D., University of Bradford, School of Information Sciences, UK
- *2003.09-2006.09*, Master-Ph.D. Combined Program, Sun Yat-sen University, School of Mathematics and Computational Science
- *1999.09-2003.06*, Bachelor's Degree, Sun Yat-sen University, School of Mathematics and Computational Science

# üë©‚Äçüè´ Work Experiences
<!-- - *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->
- *2013.03-Present*, Associate Professor, South China University of Technology, School of Electronic and Information Engineering
- *2022.12-2023.12*, Visiting Scholar, University of Lincoln, UK
- *2017.07-2018.07*, Visiting Scholar, University of Strathclyde, UK
- *2011.03-2011.05*, Visiting Scholar, Microsoft Research Cambridge, UK
- *2010.02-2013.01*, Postdoctoral Researcher, University of Lincoln, UK

# üìù Publications 

## üòÑ Sentiment Analysis
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TAFFC 2024</div><img src='images/MASANet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MASANet: Multi-Aspect Semantic Auxiliary Network for Visual Sentiment Analysis](https://ieeexplore.ieee.org/document/10380727)

**Jinglun Cen**, Chunmei Qing*, Haochun Ou, Xiangmin Xu, and Junpeng Tan

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=soX8e10AAAAJ&cstart=20&pagesize=80&citation_for_view=soX8e10AAAAJ:zA6iFVUQeVQC) <strong><span class='show_paper_citations' data='soX8e10AAAAJ:zA6iFVUQeVQC'></span></strong>
- We propose a Multi-Aspect Semantic Auxiliary Network (MASANet) for visual sentiment analysis. Specifically, MASANet achieves modality expansion through cross-modal generation, making it possible to introduce cross-domain semantic assistance. Then, a cross-modal gating module and an adaptive modal fusion module are proposed for aspect-level and cross-modal interaction, respectively. In addition, a designed semantic polarity constraint loss is presented to improve sentiment multi-classification performance.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TASLP 2023</div><img src='images/CAMFNet.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Context-Based Adaptive Multimodal Fusion Network for Continuous Frame-Level Sentiment Prediction](https://ieeexplore.ieee.org/document/10271721)

**Maochun Huang**, Chunmei Qing*, Junpeng Tan, and Xiangmin Xu

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=soX8e10AAAAJ&sortby=pubdate&citation_for_view=soX8e10AAAAJ:2P1L_qKh6hAC) <strong><span class='show_paper_citations' data='soX8e10AAAAJ:2P1L_qKh6hAC'></span></strong>
- We propose a novel Context-Based Adaptive Multimodal Fusion Network (CAMFNet) for consecutive frame-level sentiment prediction. A Context-based Transformer (CBT) module was specifically designed to embed clip features into continuous frame features, leveraging its capability to enhance the consistency of prediction results. Moreover, to resolve the multi-modal conflict between modalities, this article proposed an Adaptive multimodal fusion (AMF) method based on the selfattention mechanism. It can dynamically determines the degree of shared semantics across modalities, enabling the model to flexibly adapt its fusion strategy. 
</div>
</div>

## üß† fNIRS Projects 
<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CEI 2024</div><img src='images/REFN.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

REFN: A Multimodal Database for Emotion Analysis Using Functional Near-infrared Spectroscopy

**Dengjun Sun**, Chunmei Qing*, Zhili Lai1, and Xiangmin Xu

<!-- [**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=soX8e10AAAAJ&sortby=pubdate&citation_for_view=soX8e10AAAAJ:2P1L_qKh6hAC) <strong><span class='show_paper_citations' data='soX8e10AAAAJ:2P1L_qKh6hAC'></span></strong> -->
[**Data**](https://github.com/DrChunmeiQing/REFN)
- We present a multimodal affective dataset based on fNIRS, comprising recordings from 28 participants observing five categories of emotional videos (pride, happy, neutral, fear, sad). The dataset includes fNIRS data, Galvanic Skin Response (GSR) data, Photoplethysmographic (PPG) data, and facial expressions data. 
</div>
</div>


# üéñ Honors and Awards
<!-- - *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. -->
- Won the First Prize of Natural Science in Guangdong Province.
- Gave an oral presentation at the top international AI conference AAAI 2023.
- Received the Best Demonstration Paper Award at the well-known international conference BICS 2023.
- Gave an oral presentation at the top international VR conference IEEE VR 2020.
- Graduate students have won the championship and runner-up in domestic AI competitions multiple times.
- Received the Best Student Paper Award at ICCSS 2017.
- Received the Best Paper Nomination Award at the well-known international image processing conference ICIP 2017.

# üß¢ Positions
<!-- - *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->
- Member of the Specialized Committee on Affective Computing of the China Graphics and Image Society (CGIS)
- Director of Transmedia Technology Department, Human Data Sensing Engineering Research Center, Ministry of Education, China
- Secretary of Guangdong Key Laboratory of Digital Twins
- Vice Chairman and Secretary General of Guangdong Applied Brain Science Industry Technology Innovation Alliance
- Secretary of IEEE CASS Guangzhou chapter

# üíª Research Projects
<!-- - *2019.05 - 2020.02*, [Lorem](https://github.com/), China. -->
- *2023-2025*, Research on the Influence of Virtual Reality Technology on the Perception of Environmental Risk, Guangdong Provincial Natural Science Foundation.
- *2022-2023*, Research on the Multimodal Emotion Recognition Based on Human-Computer Interaction, Guangdong Provincial Natural Science Foundation.
- *2021-2022*, VR/AR Technology-Driven Research on Disaster Risk Awareness, Guangdong Provincial Natural Science Foundation.
- *2015-2017*, Research on the Adaptability of Mobile and Immersive Visualization for Environmental Risk Communication, Guangdong Provincial Natural Science Foundation.
- *2015-2016*, Research on the Capacity of Artificial Intelligence to Support Disaster Risk Reduction Strategies, Guangdong Provincial Science and Technology Project (Major Technology Project).
